{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-07T19:29:29.810396Z"
    }
   },
   "source": [
    "import os, time, math, json\n",
    "from typing import Iterator, Tuple\n",
    "import multiprocessing\n",
    "# safe import of BrokenProcessPool\n",
    "try:\n",
    "    from concurrent.futures.process import BrokenProcessPool\n",
    "except Exception:\n",
    "    class BrokenProcessPool(Exception):\n",
    "        pass\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    TQDM = True\n",
    "except Exception:\n",
    "    TQDM = False\n",
    "# ---------------- Worker (top-level for multiprocessing) ----------------\n",
    "def worker_compute_range(start_end: Tuple[int,int]) -> Tuple[int,int,int,int,str]:\n",
    "    \"\"\"\n",
    "    Обробити інтервал [start, end).\n",
    "    Повертає (start, end, total_steps, count, error_msg)\n",
    "    error_msg == '' при успіху.\n",
    "    Локальний memo реалізує \"еволюцію даних\" всередині воркера.\n",
    "    \"\"\"\n",
    "    start, end = start_end\n",
    "    try:\n",
    "        memo = {1: 0}\n",
    "        total_steps = 0\n",
    "        # перебираємо кожне n в інтервалі\n",
    "        for n in range(start, end):\n",
    "            x = n\n",
    "            path = []\n",
    "            # рухаємось по градині поки не знайдемо відоме значення\n",
    "            while x not in memo:\n",
    "                path.append(x)\n",
    "                if (x & 1) == 0:\n",
    "                    x = x >> 1\n",
    "                else:\n",
    "                    x = 3 * x + 1\n",
    "            # тепер x в memo\n",
    "            known = memo[x]\n",
    "            # кількість кроків для n = len(path) + known\n",
    "            total_steps += len(path) + known\n",
    "            # заповнюємо memo для пройденого шляху (зворотнім записом)\n",
    "            cur = len(path) + known\n",
    "            for v in path:\n",
    "                memo[v] = cur\n",
    "                cur -= 1\n",
    "        return start, end, total_steps, (end - start), ''\n",
    "    except Exception as e:\n",
    "        return start, end, 0, 0, f\"{type(e).__name__}: {e}\"\n",
    "# ---------------- Помічники ----------------\n",
    "def chunk_ranges_gen(N:int, chunk_size:int) -> Iterator[Tuple[int,int]]:\n",
    "    \"\"\"Генератор інтервалів [1..N] в головному потоці.\"\"\"\n",
    "    start = 1\n",
    "    while start <= N:\n",
    "        end = min(start + chunk_size, N + 1)\n",
    "        yield (start, end)\n",
    "        start = end\n",
    "# ---------------- Основний виконавець (multiprocessing.Pool, з fallback на sequential) ----------------\n",
    "def compute_collatz(\n",
    "    N: int = 10_000_000,\n",
    "    chunk_size: int = 50_000,\n",
    "    workers: int = None,\n",
    "    use_threads: bool = False,\n",
    "    checkpoint_path: str = \"collatz_checkpoint.json\",\n",
    "    checkpoint_every: int = 10,\n",
    "    maxtasksperchild: int = 100\n",
    "):\n",
    "    \"\"\"\n",
    "    Паралельний запуск (рекомендовано: процеси).\n",
    "    Повертає (avg_steps, total_steps, total_count, elapsed_seconds).\n",
    "    \"\"\"\n",
    "    if N < 1:\n",
    "        raise ValueError(\"N має бути >= 1\")\n",
    "    if workers is None:\n",
    "        cpu = os.cpu_count() or 1\n",
    "        workers = max(1, cpu - 1)\n",
    "    total_tasks = math.ceil(N / chunk_size)\n",
    "    print(f\"Параметри: N={N}, chunk_size={chunk_size}, total_tasks={total_tasks}, workers={workers}, use_threads={use_threads}\")\n",
    "    # відновлення з чекпоінту, якщо є\n",
    "    resume_state = None\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            with open(checkpoint_path, 'r') as f:\n",
    "                resume_state = json.load(f)\n",
    "            print(\"Знайдено чекпоінт. Відновлюємо прогрес:\", resume_state.get('completed_tasks',0), \"з\", total_tasks, \"задач\")\n",
    "        except Exception as e:\n",
    "            print(\"Не вдалося прочитати чекпоінт:\", e)\n",
    "            resume_state = None\n",
    "    # підготовка генератора й пропуск завершених задач при відновленні\n",
    "    chunks_iter = chunk_ranges_gen(N, chunk_size)\n",
    "    if resume_state:\n",
    "        skip = resume_state.get('completed_tasks', 0)\n",
    "        for _ in range(skip):\n",
    "            try:\n",
    "                next(chunks_iter)\n",
    "            except StopIteration:\n",
    "                break\n",
    "    total_steps = 0 if resume_state is None else resume_state.get('total_steps', 0)\n",
    "    total_count = 0 if resume_state is None else resume_state.get('total_count', 0)\n",
    "    completed = 0 if resume_state is None else resume_state.get('completed_tasks', 0)\n",
    "    start_time = time.perf_counter()\n",
    "    # Використовуємо multiprocessing.Pool, який звичайно стабільніший на великих прогонах\n",
    "    try:\n",
    "        print(f\"Запускаємо multiprocessing.Pool (processes={workers}, maxtasksperchild={maxtasksperchild}) ...\")\n",
    "        pool = multiprocessing.Pool(processes=workers, maxtasksperchild=maxtasksperchild)\n",
    "        try:\n",
    "            # imap_unordered повертає по мірі готовності результатів\n",
    "            it = pool.imap_unordered(worker_compute_range, chunks_iter, chunksize=1)\n",
    "            pbar = tqdm(total=total_tasks, desc=\"tasks\", unit=\"task\") if TQDM else None\n",
    "            if pbar and resume_state:\n",
    "                pbar.update(resume_state.get('completed_tasks', 0))\n",
    "            for res in it:\n",
    "                s_start, s_end, s_total_steps, s_count, s_err = res\n",
    "                if s_err:\n",
    "                    # якщо воркер вернув помилку, обробляємо цей chunk послідовно в головному процесі (fallback)\n",
    "                    print(f\"Помилка в воркері для chunk {s_start}-{s_end}: {s_err}. Виконуємо послідовний fallback для цього chunk'а.\")\n",
    "                    s_start, s_end, s_total_steps, s_count, s_err2 = worker_compute_range((s_start, s_end))\n",
    "                    if s_err2:\n",
    "                        print(f\"Fallback також зафейлився для {s_start}-{s_end}: {s_err2}. Пропускаємо цей chunk.\")\n",
    "                        s_total_steps = 0\n",
    "                        s_count = 0\n",
    "                total_steps += int(s_total_steps)\n",
    "                total_count += int(s_count)\n",
    "                completed += 1\n",
    "                if pbar:\n",
    "                    pbar.update(1)\n",
    "                # чекпоінтінг\n",
    "                if checkpoint_path and (completed % checkpoint_every == 0):\n",
    "                    with open(checkpoint_path, 'w') as f:\n",
    "                        json.dump({\n",
    "                            'total_steps': total_steps,\n",
    "                            'total_count': total_count,\n",
    "                            'completed_tasks': completed,\n",
    "                            'N': N,\n",
    "                            'chunk_size': chunk_size\n",
    "                        }, f)\n",
    "            if pbar:\n",
    "                pbar.close()\n",
    "        finally:\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "        elapsed = time.perf_counter() - start_time\n",
    "        avg = total_steps / total_count if total_count else 0.0\n",
    "        print(\"[multiprocessing.Pool] Завершено успішно.\")\n",
    "        return avg, total_steps, total_count, elapsed\n",
    "    except Exception as e:\n",
    "        # якщо Pool зламався — робимо послідовну обробку як останній fallback\n",
    "        print(\"[multiprocessing.Pool] Exception:\", type(e).__name__, e)\n",
    "        print(\"[SEQUENTIAL FALLBACK] Починаємо послідовну обробку залишку (повільно, але гарантує завершення).\")\n",
    "        seq_start = time.perf_counter()\n",
    "        for ch in chunks_iter:\n",
    "            s_start, s_end, s_total_steps, s_count, s_err = worker_compute_range(ch)\n",
    "            if s_err:\n",
    "                print(f\"[SEQUENTIAL] Error for chunk {ch}: {s_err} — пропускаємо.\")\n",
    "            total_steps += int(s_total_steps)\n",
    "            total_count += int(s_count)\n",
    "            completed += 1\n",
    "            if checkpoint_path and (completed % checkpoint_every == 0):\n",
    "                with open(checkpoint_path, 'w') as f:\n",
    "                    json.dump({\n",
    "                        'total_steps': total_steps,\n",
    "                        'total_count': total_count,\n",
    "                        'completed_tasks': completed,\n",
    "                        'N': N,\n",
    "                        'chunk_size': chunk_size\n",
    "                    }, f)\n",
    "        seq_elapsed = time.perf_counter() - seq_start\n",
    "        elapsed = time.perf_counter() - start_time\n",
    "        avg = total_steps / total_count if total_count else 0.0\n",
    "        return avg, total_steps, total_count, elapsed\n",
    "# ---------------- Виконання ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        multiprocessing.freeze_support()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # --------- Налаштування (змініть під вашу машину при потребі) ----------\n",
    "    N = 10_000_000\n",
    "    CHUNK_SIZE = 100_000\n",
    "    CPU = os.cpu_count() or 1\n",
    "    WORKERS = 4\n",
    "    USE_THREADS = True\n",
    "    CHECKPOINT = \"collatz_checkpoint.json\"\n",
    "    CHECKPOINT_EVERY = 10\n",
    "    MAxTASKS = 100\n",
    "    print(\"Починаємо обчислення (Ctrl+C для переривання). Параметри:\")\n",
    "    print(f\" N={N}, CHUNK_SIZE={CHUNK_SIZE}, WORKERS={WORKERS}, USE_THREADS={USE_THREADS}, CHECKPOINT={CHECKPOINT}\")\n",
    "    t0 = time.perf_counter()\n",
    "    avg, tot_steps, tot_count, elapsed = compute_collatz(\n",
    "        N=N,\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        workers=WORKERS,\n",
    "        use_threads=USE_THREADS,\n",
    "        checkpoint_path=CHECKPOINT,\n",
    "        checkpoint_every=CHECKPOINT_EVERY,\n",
    "        maxtasksperchild=MAxTASKS\n",
    "    )\n",
    "    t_total = time.perf_counter() - t0\n",
    "    print(\"\\n=== РЕЗУЛЬТАТ ===\")\n",
    "    print(f\"Оброблено чисел: {tot_count:,}\")\n",
    "    print(f\"Загальна сума кроків: {tot_steps:,}\")\n",
    "    print(f\"Середня кількість кроків на число: {avg:.6f}\")\n",
    "    print(f\"Час виконання воркерів (приблизно): {elapsed:.2f} с\")\n",
    "    print(f\"Повний час (wall-clock): {t_total:.2f} с\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Починаємо обчислення (Ctrl+C для переривання). Параметри:\n",
      " N=10000000, CHUNK_SIZE=100000, WORKERS=4, USE_THREADS=True, CHECKPOINT=collatz_checkpoint.json\n",
      "Параметри: N=10000000, chunk_size=100000, total_tasks=100, workers=4, use_threads=True\n",
      "Запускаємо multiprocessing.Pool (processes=4, maxtasksperchild=100) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tasks:   0%|          | 0/100 [00:00<?, ?task/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
